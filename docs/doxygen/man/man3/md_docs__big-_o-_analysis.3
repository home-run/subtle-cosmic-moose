.TH "md_docs__big-_o-_analysis" 3 "Mon May 16 2016" "Version 1.0" "Baseball Fantasy Vacation Documentation" \" -*- nroff -*-
.ad l
.nh
.SH NAME
md_docs__big-_o-_analysis \- Big-O Analysis 

.SS "Team: ~/run"
.PP
.SS "Group Members"
.PP
.IP "\(bu" 2
Jesse Mazzella
.IP "\(bu" 2
Sepher Raissaian
.IP "\(bu" 2
Daniel Phan
.IP "\(bu" 2
Dan Karlsson
.PP
.PP
.SS "Algorithms"
.PP
.IP "\(bu" 2
Dijkstra’s Algorithm
.IP "\(bu" 2
Minimum Spanning Tree - Prims
.PP
.PP
.SS "Data Structures"
.PP
.IP "\(bu" 2
\fBGraph\fP [Adjacency List – Priority Queue]
.IP "\(bu" 2
\fBGraph\fP [Adjacency Matrix]
.IP "\(bu" 2
\fBHeap\fP [Priority Queue]
.IP "\(bu" 2
\fBVertexSet\fP [Set]
.IP "\(bu" 2
\fBQStack\fP
.IP "\(bu" 2
\fBQVector\fP
.IP "\(bu" 2
\fBQList\fP
.IP "\(bu" 2
\fBQMap\fP
.PP
.PP
.SS "Algorithms"
.PP
.SS "Dijkstra's Algorithm"
.PP
.PP
.PP
Dijkstra's Algorithm is used for finding the shortest paths between vertices stored within a graph\&. The implementation of Dijsktra's algorithm is a variant of the original and finds the shortest path between a source node and all other nodes within a graph\&. It uses a minimum-heap priority queue to improve the efficiency of the algorithm when determining the path\&.
.PP
\fBAlgorithm\fP: void \fBGraph::shortestPath(Vertex source)\fP
.PP
.PP
.nf
source = vertexList\&.at(source\&.getId());
// Initialize all edges, and vertices to infinity
initialize_single_source(source);
.fi
.PP
.PP
Function: void Graph::initialize_single_source(Vertex source)
.PP
This runs in \fBO(n)\fP because \fCinitialize_single_source(source)\fP will iterate through each vertex in the graph and initialize each vertex with a distance of \fIINFINITY\fP and the parent to _-1_\&. Then it sets the source vertex to have a distance of 0 to represent it as being the starting vertex\&.
.PP
.PP
.nf
for(int vertex = 0; vertex < numVertices;vertex++)  // O(n) performance
    vertexList[vertex]\&.setDistance(INF);
    vertexList[vertex]\&.setParent(-1);

vertexList[s\&.getId()]\&.setDistance(0);
.fi
.PP
 This process is then
.PP
.RS 4
\fBInitialize each vertex in the graph => O(n)\fP 
.RE
.PP
.PP
Then it will initial a vertex set class to be empty and insert the starting vertex into the priority queue of vertices to grab from\&. This operation is done in \fBO(1)\fP time since the priority queue is empty at this point\&.
.PP
.PP
.nf
T\&.clear();
vertexPQ\&.insert(vertexList[source\&.getId()]);    // O(1) performance
.fi
.PP
.PP
.RS 4
\fBInsert into an empty priority queue => O(1)\fP 
.RE
.PP
.PP
Dijkstra's algorithm will run for as many vertices that there are in the graph what there are \fBn\fP number of vertices\&. This gives \fBO(n)\fP performance because the algorithm has the check \fBn\fP number of vertices\&.
.PP
The removal of a vertex from the priority queue is \fBO(logn)\fP because the removal itself takes \fBO(1)\fP but the \fIbubble down\fP / \fImin-heapify\fP process after the remove of a node from priority queue will take \fBO(logn)\fP\&.
.PP
.PP
.nf
while(!vertexPQ\&.isEmpty()){

    u = vertexPQ\&.removeMin();   // O(logn)
.fi
.PP
.PP
>__Removal of a node => O(1 + logn) ==> O(logn)__ but is only done for each vertex in the graph => O(n)
.PP
Next the algorithm will check each vertex to see the adjacent edges have a distance sum of the current vertex plus the weight of the edge is smaller than the distance currently found for the next vertex\&. Each edge to that vertex is stored within its own priority queue which gives it \fBO(1)\fP access for retrieving the smallest weighted edge to that vertex, but calling \fCgetNearestEdge()\fP also removes the edge from the priority queue there for producing a \fBO(logn)\fP performance and allowing the next smallest edge being readily accessible\&.
.PP
.PP
.nf
while(vertexList\&.at(u\&.getId())\&.hasEdges()){

    adjEdge = vertexList[u\&.getId()]\&.getNearestEdge();                               // <= O(logn)
    v = vertexList\&.at(adjEdge\&.idTo);                                                // <= O(1)

    if(adjacencyMatrix[u\&.getId()][adjEdge\&.idTo] != 0){

        distanceSum = u\&.getDistance() + adjacencyMatrix[u\&.getId()][v\&.getId()];      // <= O(1)

        if(v\&.getDistance() > distanceSum )                                          // <= O(1)
            v\&.setDistance(distanceSum);                                             // <= O(1)
            v\&.setParent(u\&.getId());                                                 // <= O(1)
            vertexList[v\&.getId()] = v;                                              // <= O(1)

        // If the set T of found vertices does not contain the vertex v add the
        //  vertex v to the priority queue to see the shorter path\&.
        if(!T\&.contains(v))          // <= Expected O(1) worst case O(n)
            vertexPQ\&.insert(v);     // <= O(logn)
            T\&.insert(v);            // <= Expected O(1) worst case O(n)
.fi
.PP
 The removal and checking of edges is a O(e) [\fBEdge\fP per node] process since it has to check each adjacent edge for each vertex and each edge has to be checked\&. Therefore,
.PP
.RS 4
Removal and checking of each edge ==> O(e) 
.RE
.PP
.PP
Since it utilizes a priorty queue to sort the vertices by its current distance it allows the checking off vertices from \fBO(n)\fP to \fBO(logn)\fP for each adjacent vertex\&.
.PP
.RS 4
Checking adjacent vertices for each vertex in the priority queue => O(nlogn) but since it only needs to check the vertices 
.RE
.PP
.PP
.RS 4
\fBInitialize each vertices => O(n) + Insert into priority queue => O(1) + Removal of a node => O(n) + Removal and checking of each edge ==> O(e) + Checking adjacent vertices for each vertex => O(nlogn)\fP
.PP
\fBO(n) + O(1) + O(n) + O(e) + O(nlogn)\fP 
.RE
.PP
.PP
.SS "The resulting performance is :"
.PP
.RS 4
\fBO(2n + 1 + e + nlogn) = O(e + nlogn)\fP 
.RE
.PP
.PP
.SS "MST prim’s"
.PP
.PP
.PP
The time complexity of Prim's algorithm depends on the data structures used for the graph and for ordering the edges by weight\&.Using an adjacency matrix or an adjacency list graph representation and linearly searching an array of weights to find the minimum weight edge, to add requires O(|V|2) running time\&. However, this running time can be greatly improved further by using heaps to implement finding minimum weight edges in the algorithm's inner loop\&. A first improved version uses a heap to store all edges of the input graph, ordered by their weight\&. This leads to an O(|E| log |E|) worst-case running time\&. But storing vertices instead of edges can improve it still further\&. The heap should order the vertices by the smallest edge-weight that connects them to any vertex in the partially constructed minimum spanning tree (MST) (or infinity if no such edge exists)\&. Every time a vertex v is chosen and added to the MST, a decrease-key operation is performed on all vertices w outside the partial MST such that v is connected to w, setting the key to the minimum of its previous value and the edge cost of (v,w)\&.
.PP
\fBAlgorithm\fP: long \fBGraph::minimumSpanningTree(int source)\fP
.PP
Initialize each vertex in the list, key, and mstSet to INFINITY and not found;
.PP
.PP
.nf
for(int i = 0; i < numVertices; i++)        // <== O(n)
    key[i] = INF;
    mstSet[i] = false;
    vertexList[i]\&.setParent(-1);
    vertexList[i]\&.setDistance(INF);
key[source] = 0;                            // <== O(1)
parent[source] = -1;                        // <== O(1)
.fi
.PP
.PP
.RS 4
\fBInitialization takes O(n)\fP 
.RE
.PP
.PP
for each vertex in the graph find the minimum weight adjacent edge and set it as discovered 
.PP
.nf
for(int count = 0; count < numVertices; count++) // <== O(n)
    int u = minKey(key, mstSet);
    mstSet[u] = true;

.fi
.PP
.PP
\fBAlgorithm\fP: long \fBGraph::minKey(long key[], bool mstSet[])\fP 
.PP
.nf
long min = INF;
long min_index;
for(int v = 0; v < numVertices; v++)            // <== O(n)
    if(mstSet[v] == false && key[v] < min)
        min = key[v];
        min_index = v;

return min_index;

.fi
.PP
.PP
.RS 4
\fBProcess to find the minimum edge is O(n*n) => O(n^2)\fP 
.RE
.PP
.PP
Checking every edge that is adjacent to the current edge and to see if it has already been visited is a \fBO(n)\fP process\&. 
.PP
.nf
for(int v = 0; v < numVertices; v++)         // <== O(n)

    if (adjacencyMatrix[u][v] > 0 && mstSet[v] == false && adjacencyMatrix[u][v] < key[v])
        parent[v] = u;
        vertexList[v]\&.setParent(u);
        key[v] = adjacencyMatrix[u][v];
        vertexList[v]\&.setDistance(key[v]);

.fi
.PP
.PP
.RS 4
\fBProcess to find the vertex with the smallest possible weight which has not been discovered for each vertex is O(n*n)\fP 
.RE
.PP
.PP
.RS 4
\fBSince the process takes n + n^2 + n^2\fP 
.RE
.PP
.PP
.RS 4
\fBO(n + n^2 + n^2) = O(n^2)\fP 
.RE
.PP
.PP
.SS "\fBHeap\fP"
.PP
\fBHeap\fP worst case,best case and average case are \fBO(nlogn)\fP The buildMaxHeap() operation is run once, and is \fBO(n)\fP in performance\&. The bubbleDown() function is \fBO(log(n))\fP, and is called \fBn\fP times\&. Therefore, the performance of this algorithm is \fBO(n + n * log(n))\fP which evaluates to \fBO(n log n)\fP\&. Also, the bubbleDown version of heapify has \fBO(n)\fP time complexity, while the bubbleUp version given below has \fBO(n log n)\fP time complexity due to its equivalence with inserting each element, one at a time, into an empty heap\&. 
